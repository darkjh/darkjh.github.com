---
layout: post
title: "Algorithm Revision: Basics"
description: "算法复习小记，基础部分"
tags: [algorithm, learning notes]
---
真正开始读info也有近两年时间，总是觉得自己基础非常薄弱,特别在算法和数据结构这块方面. 所以趁着这次假期有空(最后一个暑假...), 研究一下[算法导论(CLRS)][1], 目标不求成为精通算法的高玩们, 但愿面试的时候能忽悠几句, 磊码用到的时候有个概念就好.

## 算法基础部分 ##
### 算法正确性与循环不变式 ###

作为一种解决问题的工具, 算法的正确性是首先要关注的. 算法正确性(correcteness)通常是由循环不变式(invariant)经过数学归纳法(mathematical induction)进行证明的. 首先, 对于循环不变式, 我把它理解为一种数学思想, 即通过推广某种局部的正确性来证明全局的正确性. 通过算法中循环的执行(通常是迭代), 把这种正确性一点一点地推广到问题的全体上去. 也就是说在循环的每一步, 我们都把这个具有正确性的子集增大了一点, 直到这个子集扩大到它的极限, 即全体, 算法的正确性也就得到证明了.

这样来证明一个算法的正确性, 通常分为三步, 分别是循环不变式的三个性质:

  + __初始化__: 不变式在迭代开始之前, 应该是正确的
  + __保持__: 经过一次迭代之后, 不变式应该保持其正确性
  + __终止__: 循环结束后, 该不变式能够有助于表明算法的正确性

举个简要的例子: 建立最大堆的算法. 循环的每一次迭代对非叶子节点做一个向下调整.

{% highlight c linenos%}
Build-Max-Heap (A)
  A.heap-size <- A.length
  for i <- A.length/2 downto 1 do
	  Max-Heapify (A, i)
{% endhighlight %}

3~4行for循环的不变式是: 节点`i`到节点`n`均满足最大堆的定义, 这些节点都是一个最大堆的根.
证明:

  + __初始化__: 从`length / 2`到`n`, 均为叶子节点, 满足最大堆定义
  + __保持__: 在循环中, `max-heapify`被调用. 这个函数将一个节点向下调整到满足堆定义的某个位置. 函数返回之后节点i满足堆定义. 循环不变式保持.
  + __终止__: 循环结束时, i为0, 从第一个节点到最后一个节点n均满足最大堆定义. 所以整个二叉树的所有节点满足最大堆定义, 该算法成功的建立了一个最大堆.

### 渐进记号和算法分析 ###

为了使算法分析和具体的技术细节无关(硬件, 架构 ...), 算法分析对算法的运行做了一定的简化和和抽象. 通常我们假定问题的规模足够大, 决定算法效率的只是其运行资源的量级增长而忽略其他一些次要的因素. 为了表达这种思想算法分析中引入了渐进记号. 在渐进记号的表达中, 我们忽略常数系数以及低阶项, 比如`\(O(3n^2+5n+4)\)`渐进的来看等同于`\(O(n^2)\)`.

算法分析中常用三种渐进记号: `\(O\)`表示有渐进上界, `\(\Omega\)`表示渐进下界. 如果上下界均存在使用`\(\Theta\)`.

在分析算法的时候, 需要按输入的不同情况进行讨论: 最佳情况, 最差情况和平均情况. 最佳情况和最差情况都是针对某一种特别的输入来分析的, 比如对于基本的排序算法, 已排序和逆排序通常就是最佳和最差情况的输入. 而分析平均情况的时候, 我们需要假设所有可能的输入满足输入集合上的平均分布, 他们出现的概率均等. 通常需要使用求随机变量期望的方法来求解. 对于算法分析我们感兴趣的是最坏情况和平均情况分析, 因为它使我们能够有一个算法运行时间上的保证.

### 极限测试(limit test) ###

极限测试可以很方便的用来分析两个渐进式的关系

  + 首先计算
  `\[c=\lim_{n\rightarrow\infty}\frac{f(n)}{g(n)}\]`
  + 如果`\(c=0\)`, 那么`\(f(n)\in o(g(n))\)`
  + 如果`\(0<c<\infty\)`, 那么`\(f(n)\in \Theta(g(n))\)`
  + 如果`\(c=\infty\)`, 那么`\(f(n)\in\omega(g(n))\)`

比如两个式子, `\(log(n)\)`和`\(n^a\)`, `\(a>0\)`
`\[
c=\lim_{n\rightarrow\infty}\frac{log(n)}{n^a}=\lim_{n\rightarrow\infty}\frac{\frac{1}{n}}{an^{a-1}}=\lim_{n\rightarrow\infty}\frac{1}{an^a}=0
\]`
所以, 任何对数式渐进小于任意的多项式.

再比如, `\(n^2\)`和`\(log(n)^{log(n)}\)`
`\[
log(n)^{log(n)}=2^{lg(lg(n))lg(n)}=n^{lg(lg(n))} \\
c=n^{lglgn-2}=\infty
\]`
所以`\(n^{2}\in o(log(n)^{log(n)})\)`.

### 递归分析和主定理 ###

在分析分治算法或递归算法的时候, 会遇到递归形式表示的运行时间. 比如二分查找: `\(T(n) = T(n/2)+O(1)\)`. 解这类递归式的方法有两种:

   + __递归树(recursion tree)__ 顾名思义, 画出递归分支树进行分析, 推导出树的高度以及每一层的消耗. 把每层的消耗相加即是这个递归式的解的一个猜测. 然后使用代换法(substitution method)证明这个猜测.
   + __主方法(master method)__ [主方法][2]名字听起来有点奇怪... 但是它为递归分析提供了"对号入座"的解. 其证明比较复杂.

递归树结合代换法证明的方法可以用于任何递归式的求解, 但这种方法相对比较复杂而且需要良好的数学基础(不适合我). 而相对直观的主方法只适用于形如`\(T(n)=aT(n/b)+f(n)\)`的递归式. 除此之外, 有一点要注意的是, 主方法中`\(log_b^a\)`式必须`多项式`的大于或小于`\(f(n)\)`, 否则主方法不适用.

下面举两个例子:

+ `\(T(n)=T(\sqrt(n))+lglgn\)`

`\[
\text{变量代换  } m=lg(n) \\
\text{因  } m/2=lg(n^\frac{1}{2}) \text{  有  } S(m)=S(m/2)+\Theta(lg(m)) \\
log_b^a = log_2^1 = 0 \Rightarrow m^{log_b^a}=m^0=1 \\
\frac{f(m)}{n^{log_b^a}}=lg(m)=O(n^\epsilon) \Rightarrow \text{1不是多项式的小于f(n), 主方法不适用}
\]`

虽然如此, 利用递归树方法, 可以比较容易的看出其一共有`\(lg(m)\)`层, 每层消耗至多`\(lg(m)\)`. 所以一个合理的猜测是`\(\Theta((lg(m))^2)\)`. 代换回变量n即是`\(\Theta((lglgn)^2)\)`. 可以证明这个解是最后正确的答案.

+ `\(T(n)=10T(n/3)+17n^{1.2}\)`

`\[
log_b^a = log_{3}^{10} > log_3^9 = 2 \Rightarrow n^{log_{3}^{10}} > n^{1.2} \\
\text{可以应用主方法情况一, 得} T(n)=\Theta(n^{log_{3}^{10}})
\]`

   [1]: http://www.amazon.com/Introduction-Algorithms-Thomas-H-Cormen/dp/0262033844
   [2]: http://en.wikipedia.org/wiki/Master_theorem
