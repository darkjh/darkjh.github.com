---
layout: post
title: "Algorithm Revision: Augmenting Data Structures"
description: ""
tags: [algorithm, learning notes]
---

Augmenting Data Structures可以译为数据结构的扩展. 在实践中, 很少需要自己创造出全新的数据结构, 许多情况下在现有的某种数据结构上做一些改变, 添加一些信息就可以满足应用的需求. 所以CLRS里用了一整章来讲扩展数据结构的基本方法和需要注意的问题.


## 选择问题 ##

在讲快排的时候, 提到了选择问题, 即在包含n个元素的集合中, 查询得第i大的元素. 利用和快速排序相同的分治思想(相同的partition函数), 我们可以在`\(O(n)\)`时间内在任意数据结构上找到任意排位的元素. 但我们如果扩展一下红黑树的结构用于存储元素集合, 选择问题可以在__对数__时间内解决.

首先我们要在红黑树的节点中加入size属性. 其包含了以这个节点为根的子树的内部节点数(包括本节点). 这个size属性能够用递归很容易的确定出来:

`\[
size[x] = size[left[x]] + size[right[x]]+1 \qquad size[nil[T]]=0
\]`

### 查询指定排名的元素 ###

![](/images/2012-08/Aug-Ds-1.png)

在这个数据结构上, 查询操作的思路和原来选择算法是相似的. 给定根节点x和排名i, 算法从x开始下降, 计算`\(rank = size[left[x]]+1\)`即该节点的rank(左侧所有比x小的元素的个数加上他自己一个), 然后和i相比较

 + `\(i=rank\)`, 那么我们已经找到了答案, 返回x
 + `\(i \lt rank\)`, 那么意味着第i小的元素在x的左子树里, 那么在`\(left[x]\)`上递归调用, i不变
 + `\(i \gt rank\)`, 这里意味着第i小的元素在x的右子树里, 同样是对右子树递归调用, 但是注意在右子树里, 排名不是i, 而是i-r

这个算法每次调用都在树中下降一层, 对于红黑树, 其复杂度是对数的.

如果给定了一个节点的指针z, 希望知道这个节点的rank, 那么也很简单, 只需要在该节点上升到根节点的过程中, 将所有的以左兄弟为根的子树(如果有的话)的size累加到初始的`\(size[left[z]+1]\)`就可以了(也就是计算中序遍历树时排在z左边的节点的数量).

### 还要考虑的问题 ###

再对数据结构做了修改, 设计了查询算法之后, 还要考虑的问题就是对数据结构的维护操作(插入和删除). 红黑树为了保持性质, 插入删除的时候要改变节点颜色和做旋转. 这里只有旋转操作会改变节点size的值.
所以要在旋转操作的代码中加入两行来保持size属性, 假设y是x的右儿子而且我们在x上做左旋转:

{% highlight c %}
size[y] <- size[x]
size[x] <- size[left[x]] + size[right[x] + 1
{% endhighlight %}

同样的, 我们需要在插入的时候沿着下降路径把插入节点的size累加到路径上的节点的size属性中, 在删除的时候则反向沿着这个路径更新size.

那么插入和删除时候, 为了维护size信息而附加的额外操作最多消耗`\(O(lg(n))\)`的时间.


## 红黑树的扩展 ##

上面的选择问题是红黑树扩展的一个例子. CLRS上总结了数据结构扩展的一般模式:

 1. 选择基础数据结构
 2. 确定要在基础结构中添加的附加信息
 3. 验证可以使用基础数据结构上的基本操作来维护新添加的信息
 4. 设计新的操作

选择问题的例子就是按照这个模式来设计的. 之所以在节点中加入size属性而不是直接加入每个节点的rank, 就是考虑到了第三点, 维护问题. 如果节点中附加的是rank, 那么当一个最小元素被插入到集合中时, 那么更新的时间必定是`\(O(n)\)`, 超过了红黑树的基本操作时间.

对于红黑树(或者任意平衡查找树, BBST), 可以证明, 当某节点x中的附加信息f[x]可以仅使用x本身和其左右儿子来计算时, 我们可以用`\(O(lg(n)\)`的渐进时间来维护这些附加信息. 比如说, 假如在红黑树的节点中添加了当前节点的黑高度(black-height)为附加信息的话, 那么因为黑高度可以由左右子女和自己的颜色所计算出, 所以我们可以在不影响红黑树性能的前提下维护这个附加信息. 相反的, 如果我们要添加每个节点的深度(depth)作为附加信息, 那么则行不通. 因为节点的深度取决于节点的父亲, 而不是子女. 假设根节点的深度改变了, 那么剩下n-1个节点的深度信息都要被更新, 所以添加这个信息会影响到原有红黑树的性能, 不是一个好的设计.

另外有两个红黑树扩展的例子是CLRS上的区间树和MIT课程problem set里的平面点集问题(最后引深到了k-d tree).
