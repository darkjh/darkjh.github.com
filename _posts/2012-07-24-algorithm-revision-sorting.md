---
layout: post
title: "Algorithm Revision: Sorting"
description: "算法复习小记, 排序部分"
tags: [algorithm, learning notes]
---

## 排序 ##

排序问题(sorting)是理论计算机研究当中最基本也是研究最为深入的一个部分. 下面几个有趣的事实体现了排序在信息科学里的重要性:

 + 超过25%的cpu时间花在了排序上
 + 各种各样的应用里需要用到排序, 哪怕只是打开手机上的联系人名单
 + 排序是很多其他算法的前置条件, 比如二分搜索(binary search)
 + 研究排序的过程中提出的很多算法设计方法被更广泛的应用到了其他领域, 比如分治法(divide-conquer-combine)

### 排序算法的模型 ###

排序的方法有很多, 有些需要`\(O(n^2)\)`时间(插入排序, 冒泡排序), 有些能够在`\(O(nlgn)\)`时间内完成n个元素的排序(快排的平均情况, 合并排序和堆排序), 而另外一些算法能够在线性时间内完成(计数排序, 桶排序等). 这些算法的复杂度的区别来源于算法本身的模型. 一种常见的排序模型是基于比较的排序, 插入排序, 快速排序等等均属于这个范畴. 在这些排序的结果当中, 各个元素的次序是基于对输入元素之间的比较来决定的.

### 比较排序, 决策树 ###

抽象的来看, 比较排序可以被视为一个决策树(decision tree). 决策树是一个颗满二叉树(complete binary tree), 其每个内部节点含有输入序列中的两个不同元素, 每个外部节点(叶子)则是输入序列的一个排列. 所以一颗决策树有`\(n!\)`个叶子节点. 下面是一个三个元素的输入序列的决策树:

                  1:2
                /     \
             < /     > \
              /         \
           2:3           1:3
           / \           / \
        < / > \       < / > \
         /     \       /     \
     (1,2,3)   1:3  (2,1,3)  2:3
               / \           / \
            < / > \       < / > \
             /     \       /     \
        (1,3,2) (3,1,2)(2,3,1) (3,2,1)

比较排序算法的每次执行即等同于遍历一次其对应的决策树从根到叶子的一条路径. 每个内部节点对应一次比较, 比较的结果决定遍历的走向(左子树还是右子树). 最终达到的叶子节点就是排序的结果.

决策树模型能够帮助我们分析比较排序的最坏情况下届. 我们忽略算法当中的控制结构, 数据移动等等操作, 只把比较次数看作时间消耗的单元. 那么显而易见的是, 决策树的高度就是最坏情况下, 一个比较排序算法需要做的比较次数. 前面提到, n个元素的序列产生的决策树有`\(n!\)`个叶子, 假设树高度h, 则有

`\[n! \leq 2^h\]`

两边取对数, 得

`\[h \geq lg(n!)\]`

根据[斯特林近似公式][1]对n阶乘的展开, 可以得到h的一个下界是`\(\Omega(nlgn)\)`. 可以看出快速排序在一般情况下, 堆排序和合并排序在最坏情况下都是最优的比较排序算法.

### 线性时间排序 ###

在一般的情况下, 普遍适用的算法都是基于比较排序模型的, 所以无法突破`\(\Omega(nlgn)\)`这个下界. 但是如果对输入数据做一定的假设, 我们可以有不依赖于比较模型的算法. 比如说当待排序数字的最大值k和其数量n接近时(准确的说是`\(k=O(n)\)`), 可以使用计数排序(counting sort). 当待排序的数字可以被视作均匀分布在某一区间上时, 可以使用桶排序(bucket sort). 这两个排序算法都不依赖于元素之间的比较, 所以能达到`\(\Omega(n)\)`的下界.


## 排序算法 ##

### 堆排序 ###

堆数据结构是一种数组对象, 它可以被视作一颗完全二叉树. 根据完全二叉树的性质, 给定一个元素下标, 其父亲和儿子节点的下标可以很快计算出来:

 + `Parent(i) <- i/2`
 + `Left-child(i) <- 2i`
 + `Right-child(i) <- 2i+1`

通常这几个函数实现的效率很高, 2的乘除都可以用移位操作来实现.

堆分为最大堆和最小堆, 前者每个节点的值必须大于等于其两个儿子的值, 后者则相反. 堆排序常用最大堆.
堆排序的基本操作有如下几个:

 + `Max-heapify` 向下调整过程, 将一个节点移动到满足最大堆性质的位置(条件是该节点以下的节点均已满足性质)
 + `Build-max-heap` 线性时间运行, 通过调用max-heapify函数在任意数组上建立一个最大堆
 + `Heapsort` 堆排序过程

一个有n个元素的堆, 其高度是`\(lg(n)\)`. 而在最坏情况下, max-heapify的向下调整需要下降整个树的高度. 所以max-heapify运行时间为`\(O(lg(n))\)`. 对于建堆过程, 需要对所有非叶子节点(`\(O(n)\)`)调用max-heapify过程, 所以一个显而易见的运行时间上界是`\(O(nlg(n))\)`. 但一个更紧确的上界是`\(O(n)\)`.

有了堆操作的两个函数, 堆排序首先把待排序数组建立成最大堆, 之后反复取出堆的第一个元素(最大值), 直到堆的大小减少到1. 运行时间为`\(O(n)+nO(lg(n))\)`即`\(O(nlg(n))\)`.

除了排序, 堆还可以被用于维护一个优先队列(priority queue).

### 合并排序 ###

合并排序是分治法的经典例子. 它把一个数组的排序问题递归的看作对该数组的两个子数组的排序问题. 当一个数组的大小为1的时候, 数组自然是有序的, 这便是递归算法的终止条件. 在这个时候, 通过一个合并函数将2个已排序的数组合并起来.

![](http://www.personal.kent.edu/~rmuhamma/Algorithms/MyAlgorithms/Sorting/Gifs/mergeSort.gif)

合并函数对于两个大小为`\(O(n)\)`的有序数组的运行时间是`\(\Theta(2n)\)`. 所以可以得出合并算法的一个递归式:

`\[
T(n)=2T(n/2)+\Theta(n)
\]`

由主定理可以证明运行时间为`\(O(nlg(n))\)`. 对于合并排序没有最坏和最佳情况.

### 快速排序 ###

快速排序是应用最广的排序算法. 它在平均情况下能达到比较排序的最优下界. 快速排序在某种程度上来说也是分治法思想的一个例子. 其方法是在数组中取一个元素作为pivot, 然后把数组一分为二, 一个含有所有小于等于pivot的元素, 另一个则含有所有大于pivot的元素, 然后把pivot放在这两个子数组中间. 也就是说在这一步我们把pivot元素放在了正确的位置. 然后算法递归的作用于划分出的两个子数组, 直到数组大小为1. 简单来说, 快排的性能依赖于对于pivot的选择. 比如我们每次都能选到一个pivot, 它恰好是数组的中位数, 那么每次分割就都把数组对半分. 在这样的情况下, 快排的运行时间和合并排序相同. 更进一步, 可以证明只要划分的子数组的大小是常数倍的比率(2:3, 1:9甚至是1:99), 快排的运行时间都是`\(O(nlg(n))\)`(需要用递归树+代换法来证明). 而在最坏情况下, 每次划分我们都分出一个大小为1, 一个为n-1的子数组, 那么递归式变为

`\[
T(n)=T(1)+T(n-1)+O(n)=T(n-1)+O(n)
\]`

可以看出运行时间是二次的.

为了避免使用时候遇到某些输入序列使得算法的性能大幅降低(最坏情况), 快排实现中的pivot选择都使用了随机化技术(比如随机选择三个元素, 取其中位数为pivot). 这也就保证了算法的性能不依赖于具体输入序列.

值得一提的是, 快速排序使用的数组划分技术(partitioning)还可以用在选择问题上(selection problem). 它可以在期望线性时间内找到数组中第i大的元素.

### 计数排序 ###

当需要排序的数据都是介于0到k, 而且`\(k=O(n)\)`时, 可以采用计数排序算法来获得线性的计算时间.

计数排序的基本思想就是, 利用一个大小为k的数组C, 对于每一个输入元素x, 确定出小于x的元素个数, 记录在`C[x]`中. 之后只需要遍历一遍输入数组, 把元素x放在`C[x]+1`的位置即完成排序. 比如如果有8个元素小于x, 那么x应该放在输出数组的第九个位置上. 在实现中, 因为会出现相同的元素, 所以每放置一个元素x之后, `C[x]`的值应该减小一.

计数排序需要遍历一次辅助数组和两次输入数组, 所以复杂度为`\(O(n+k)\)`, 当前提条件满足时, 项k可以被n吸收, 所以是一个线性时间排序算法.

线性时间算法还有基数排序(radix sort)和桶排序, 有时间补上.

## 快速排序, 为什么是你? ##

同样能达到理论下界, 为什么在实践中快速排序的应用要比堆排序或合并排序要广的多呢? 快速排序的优势在于:

 + 原地排序(in-place sort), 快速排序直接移动原数组中的数据, 不需要合并排序那样大量的临时存储空间. 这在内存有限制的地方是很重要的
 + 和堆排序相比, 快速排序中, 下一个要读写的元素通常位置比较接近于当前正在操作的元素. 而堆排序经常要大范围的读写元素(把数组首位的元素放到数组末尾, 交换父元素和儿子元素等等). 算法执行过程中, 连续的元素被缓存在一起的可能性更大, 所以通常快速排序更快

虽然渐进性能相同, 但是上述两点(特别是第二点), 使得快速排序算法更有实际使用价值. 但是要注意的是, 快速排序的最坏情况仍然是`\(O(n^2)\)`(随机到的pivot很差). 所以在时间要求很严格的应用中, 一般使用的还是堆排序. 关于排序渐进式中隐藏常数的分析可以看[这里][6].

## 实现 ##

[这里][2]是一些我自己用C实现的排序算法, [这里][3]有比较齐全的排序算法实现. 以前记得有一个较完整的经典算法和数据结构的实现, 是一个斯坦福教授自己的项目, 但是现在找不到了, 找到了补上.

参考链接[一][4], [二][5], [三][7]

   [1]: http://en.wikipedia.org/wiki/Stirling%27s_approximation
   [2]: https://github.com/darkjh/Algorithm
   [3]: http://en.wikibooks.org/wiki/Algorithm_Implementation/Sorting
   [4]: http://www.personal.kent.edu/~rmuhamma/Algorithms/MyAlgorithms/Sorting/mergeSort.htm
   [5]: http://www.ics.uci.edu/~eppstein/161/960116.html
   [6]: http://www.cs.auckland.ac.nz/~jmor159/PLDS210/qsort3.html
   [7]: http://stackoverflow.com/questions/1853208/quicksort-superiority-over-heap-sort
